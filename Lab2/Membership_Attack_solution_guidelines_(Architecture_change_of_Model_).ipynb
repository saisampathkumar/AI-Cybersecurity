{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Membership Attack - solution guidelines (Architecture change of Model ).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saisampathkumar/AI-Cybersecurity/blob/master/Lab%202/Membership_Attack_solution_guidelines_(Architecture_change_of_Model_).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvK6LaVhrfZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05dkTKAsEh-",
        "colab_type": "code",
        "outputId": "b28d7fff-6ddf-4392-8c72-f0b0614f5ea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/My Drive/cybersecurity/LAB2'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEW1mLverl7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images, nothing much is needed here. \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjsFJTFwr1wV",
        "colab_type": "code",
        "outputId": "87454e61-38e9-4af4-9b20-31751c9575b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itY7G_y3tDnC",
        "colab_type": "code",
        "outputId": "553d55fd-d85b-4312-9999-b187dbc5aa08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "source": [
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " frog horse horse truck\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nluD/A/Gw8H7IkrB3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJK32k42gbEK",
        "colab_type": "code",
        "outputId": "1261a38d-c5c0-4d1e-9b11-36e871c5a68f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx =  indices[split3:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 12500 25000 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wJ_0lkhp76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aNWGWaf4mvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twelCOhJ4ou9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj9LuQJNuCXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O39H-xzClPgh",
        "colab_type": "code",
        "outputId": "4eadf884-af4c-440e-f18e-3f7ec7eaa76f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER_B4V8YjKyU",
        "colab_type": "code",
        "outputId": "82668dc3-f8ed-4d0f-9a19-60405457268f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a target model and train it\n",
        "\n",
        "target_model = CNN()\n",
        "taget_model = target_model.cuda()\n",
        "criterion = nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "optimizer = optim.Adam(target_model.parameters(), lr=0.0003) # try Adam VS SGD\n",
        "\n",
        "    \n",
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        logits = target_model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(target_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Model: \\n\\n\", target_model, '\\n')\n",
        "torch.save(target_model.state_dict(), project_path+'/target_checkpoint.pth')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.8361955096044809\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.4975736072606138\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.3142238873654923\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.1861157480560605\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.0744356593436293\n",
            "\n",
            "Epoch : 6/20.. Training loss: 0.9878842795024747\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.9145658249059296\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.8583505937205557\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.8012362808141562\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.7469205754187406\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.7141033116432712\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.6813545343859116\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6474900423737285\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.6132631803317296\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.580824503632229\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5628737886400556\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.5388317769798248\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.5135153451043627\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.4890626459227651\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.4694909526706885\n",
            "Model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpY8ktdskRQN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3a0bbb9-0b35-4a6f-dada-817ffde08e63"
      },
      "source": [
        "# calculate the accuracy of the Target Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = target_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 76 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ibJC-sA5IaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# Shadow Model Architecture\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class shadow(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(shadow, self).__init__()\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(3*32*32, 2304),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(2304, 1536),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1536, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 768),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(768, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNMRXWrY5VvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4afe131c-59e1-4f0d-b1f7-80aba38a2a0e"
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEClKFqikmUl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_VqRVVkoCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d61c799-8255-46fd-9739-46bb25f4e877"
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "shadow_model = shadow()\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()\n",
        "#send to GPU\n",
        "shadow_model = shadow_model.cuda()\n",
        "shadow_criterion =  nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "shadow_optimizer = optim.Adam(shadow_model.parameters(), lr=0.003) # ADAM \n",
        "# let the magic begin\n",
        "epochs = 20\n",
        "with torch.set_grad_enabled(True):\n",
        "  for e in range(epochs):\n",
        "      running_loss = 0\n",
        "      for images, labels in shadow_train_loader:\n",
        "          # sending tensors to GPU\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "          shadow_optimizer.zero_grad()\n",
        "          logits = shadow_model(images)\n",
        "          shadow_loss = shadow_criterion(logits, labels)\n",
        "          shadow_loss.backward()\n",
        "          shadow_optimizer.step()\n",
        "\n",
        "\n",
        "          running_loss += shadow_loss.item()\n",
        "      else:\n",
        "          print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(shadow_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Our model: \\n\\n\", shadow_model, '\\n')\n",
        "torch.save(shadow_model.state_dict(), project_path+'/shadow_checkpoint.pth')\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 2.2304690766822346\n",
            "\n",
            "Epoch : 2/20.. Training loss: 2.2337230975975464\n",
            "\n",
            "Epoch : 3/20.. Training loss: 2.269321741960238\n",
            "\n",
            "Epoch : 4/20.. Training loss: 2.25765611326603\n",
            "\n",
            "Epoch : 5/20.. Training loss: 2.245167913339327\n",
            "\n",
            "Epoch : 6/20.. Training loss: 2.2376575078195926\n",
            "\n",
            "Epoch : 7/20.. Training loss: 2.220313181047854\n",
            "\n",
            "Epoch : 8/20.. Training loss: 2.2499595839349205\n",
            "\n",
            "Epoch : 9/20.. Training loss: 2.255964306004517\n",
            "\n",
            "Epoch : 10/20.. Training loss: 2.243139540295467\n",
            "\n",
            "Epoch : 11/20.. Training loss: 2.239186163296175\n",
            "\n",
            "Epoch : 12/20.. Training loss: 2.239970878719369\n",
            "\n",
            "Epoch : 13/20.. Training loss: 2.221248025479524\n",
            "\n",
            "Epoch : 14/20.. Training loss: 2.2026334520800948\n",
            "\n",
            "Epoch : 15/20.. Training loss: 2.2050288676300926\n",
            "\n",
            "Epoch : 16/20.. Training loss: 2.2568305160688316\n",
            "\n",
            "Epoch : 17/20.. Training loss: 2.2594284528051802\n",
            "\n",
            "Epoch : 18/20.. Training loss: 2.241001554157423\n",
            "\n",
            "Epoch : 19/20.. Training loss: 2.232001443805597\n",
            "\n",
            "Epoch : 20/20.. Training loss: 2.241366777578583\n",
            "Our model: \n",
            "\n",
            " shadow(\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Linear(in_features=3072, out_features=2304, bias=True)\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Linear(in_features=2304, out_features=1536, bias=True)\n",
            "    (3): ReLU(inplace)\n",
            "    (4): Linear(in_features=1536, out_features=1024, bias=True)\n",
            "    (5): ReLU(inplace)\n",
            "    (6): Dropout(p=0.1)\n",
            "    (7): ReLU(inplace)\n",
            "    (8): Linear(in_features=1024, out_features=768, bias=True)\n",
            "    (9): ReLU(inplace)\n",
            "    (10): Linear(in_features=768, out_features=512, bias=True)\n",
            "    (11): ReLU(inplace)\n",
            "    (12): Dropout(p=0.1)\n",
            "    (13): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (14): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0kP_-62ljFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c1224cc-29b8-416d-b2f9-c98a0e8680b0"
      },
      "source": [
        "# calculate the accuracy of the Shadow Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 14 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Aani_-2062mj",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = CNN()\n",
        "    model.load_state_dict(checkpoint)\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J1B1OhMp6er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaD8_N34l3Eh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1ed78648-e502-47ed-8f6a-72ba6d918bfd"
      },
      "source": [
        "# freeze the Shadow model \n",
        "for param in shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "\n",
        "labels_0 = 0#np.zeros(1)\n",
        "labels_1 = 1#np.ones(1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "print(predictions[0])  \n",
        "print(predictions[17000])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([0.07334238, 0.09185262, 0.11069454, 0.11793382, 0.11697814,\n",
            "       0.10252736, 0.12245874, 0.11584766, 0.07048479, 0.07787981],\n",
            "      dtype=float32), 1]\n",
            "[array([0.08559339, 0.09307492, 0.1070052 , 0.11395726, 0.11108213,\n",
            "       0.09909474, 0.11628885, 0.1099307 , 0.08085928, 0.08311354],\n",
            "      dtype=float32), 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhaKjRRUl6Po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new dataset of the shape [predictions(shadow_in), 1], [predicitons(shadow_out), 0] and zip them together\n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/shadow.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl56BLIpl8Nl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "#load the model\n",
        "load_target_model = load_checkpoint(project_path+'/target_checkpoint.pth')\n",
        "load_target_model = load_target_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_target_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "label_size = (1,1)\n",
        "\n",
        "labels_0 = 0\n",
        "labels_1 = 1\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/target.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yEnRcZW6sUY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5cfa39e3-032d-4938-c256-e360183b21a1"
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UZ2tfJzl94s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/shadow.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    predictionsList = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJFbXp8umAam",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c394825a-5dc1-43ae-de20-5cc21c9154cc"
      },
      "source": [
        "total_size = len(predictionsList)\n",
        "split1 = total_size // 4\n",
        "split1 = total_size - split1 \n",
        "split2 = split1*2\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "train_idx = indices[:] \n",
        "test_idx = indices[split1:] \n",
        "print(f'No.of train date {len(train_idx)} and No.of test data {len(test_idx)}')\n",
        "batch_size = 10 # pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "train_sampler = SubsetRandomSampler(train_idx) # Pytorch function\n",
        "train_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "test_sampler = SubsetRandomSampler(test_idx) # Pytorch function\n",
        "test_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=test_sampler)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of train date 25000 and No.of test data 6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU012hhrmDvi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e51977b6-92c6-42c0-9981-b1d18c2fd797"
      },
      "source": [
        "# create the Attack Model: A NN binary classifier {0, 1}\n",
        "# the input to this model is the propability distribution vector of size 10\n",
        "# and the output is either 0 (input was not included in training) or 1\n",
        "from torch.autograd import Variable\n",
        "attack_model = nn.Sequential(nn.Linear(10, 20),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(20, 26),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(26, 16),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(16, 8),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(8, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "attack_model = attack_model.cuda()\n",
        "attack_criterion = nn.CrossEntropyLoss()\n",
        "attack_optimizer = optim.Adam(attack_model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for outputs, labels in train_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        attack_optimizer.zero_grad()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        #print(pred.data, labels)\n",
        "        loss = attack_criterion(pred, labels)\n",
        "        loss.backward()\n",
        "        attack_optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(predictionsList)}\")\n",
        "        \n",
        "torch.save(attack_model.state_dict(), project_path+'/attack_checkpoint.pth')\n",
        "print('Finished Training the Attack model')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.06932523353099823\n",
            "Training loss: 0.06933036556243896\n",
            "Training loss: 0.06933278696775437\n",
            "Training loss: 0.06932299866199493\n",
            "Training loss: 0.06932650306224823\n",
            "Finished Training the Attack model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWR_CXQEmIC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    validation = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecc2gaFmHnoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1 # pick your own\n",
        "\n",
        "validation_sampler = SubsetRandomSampler(indices[6250:18250]) # randomly picking 5000 data items\n",
        "validation_loader = torch.utils.data.DataLoader(validation, batch_size=batch_size, sampler=validation_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haNVIg-FHsFv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "14e1765a-b205-44a0-a9aa-bb5072c9ad06"
      },
      "source": [
        "#input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "total = 0\n",
        "tp = 0\n",
        "tn = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "with torch.no_grad():\n",
        "    for outputs, labels in validation_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        predicted = torch.argmax(pred.data)\n",
        "        #print('\\n',pred.data, predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.item() == labels.item())\n",
        "        tp += ((predicted.item() == labels.item()) and (predicted.item() == 1))\n",
        "        tn += ((predicted.item() == labels.item()) and (predicted.item() == 0))\n",
        "        fp += ((predicted.item() != labels.item()) and (predicted.item() == 1))\n",
        "        fn += ((predicted.item() != labels.item()) and (predicted.item() == 0))\n",
        "        #print(predicted.item(),labels.item(),correct)\n",
        "incorrect = total- correct\n",
        "print(f'TP : {tp}, TN : {tn}, FP : {fp}, FN : {fn}')\n",
        "pre = tp/(tp+fp)\n",
        "rec = tp/(tp+fn)\n",
        "print(f'Precision {pre*100}')\n",
        "print(f'Recall {rec*100}')\n",
        "print(f'F1 Score {2*((pre*rec)/(pre+rec))*100}')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TP : 6250, TN : 0, FP : 5750, FN : 0\n",
            "Precision 52.083333333333336\n",
            "Recall 100.0\n",
            "F1 Score 68.4931506849315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMsyCgziqeaa",
        "colab_type": "text"
      },
      "source": [
        "Great! At this point, you must have created a succesfful attack model that can detect whether a datapoint was used in training a target mode or not. \n",
        "* A successful attack model is one with a precision/recall higher than 85% -- you are using same architecture and are aware of the data classes\n",
        "\n",
        " \n",
        " Can you suggest any defense mechanism? If yes, Apply them to your solution and re-evaluate your attack model. How did your defense mecanism affect the accuracy of the target model? How did it affect the recall and precision of the Attack model?"
      ]
    }
  ]
}