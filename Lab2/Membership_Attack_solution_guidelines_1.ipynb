{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Membership Attack - solution guidelines 1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saisampathkumar/AI-Cybersecurity/blob/master/Lab%202/Membership_Attack_solution_guidelines_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvK6LaVhrfZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05dkTKAsEh-",
        "colab_type": "code",
        "outputId": "d84ead63-4d3f-4e36-dec9-7be25d3bb256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/My Drive/cybersecurity'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEW1mLverl7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images, nothing much is needed here. \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjsFJTFwr1wV",
        "colab_type": "code",
        "outputId": "448d37c4-9157-48a6-c6b9-dd8aad2837ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itY7G_y3tDnC",
        "colab_type": "code",
        "outputId": "33e59c1e-be93-47a5-c868-3a294f3b552c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "source": [
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " deer  deer   dog   car\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnAgZOgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJK32k42gbEK",
        "colab_type": "code",
        "outputId": "d1431e7a-9f07-40e2-9855-b6496814fbd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx =  indices[split3:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 12500 25000 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wJ_0lkhp76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj9LuQJNuCXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O39H-xzClPgh",
        "colab_type": "code",
        "outputId": "246000b4-9fc3-4905-a84a-137706d0977c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER_B4V8YjKyU",
        "colab_type": "code",
        "outputId": "984951a4-ff6a-406c-e7cb-b4dc1e48f5d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a target model and train it\n",
        "\n",
        "target_model = CNN()\n",
        "taget_model = target_model.cuda()\n",
        "criterion = nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "optimizer = optim.Adam(target_model.parameters(), lr=0.0003) # try Adam VS SGD\n",
        "\n",
        "    \n",
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        logits = target_model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(target_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Model: \\n\\n\", target_model, '\\n')\n",
        "torch.save(target_model.state_dict(), project_path+'/target_checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.7584894878022812\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.4398618028749286\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.2446832133985846\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.1145704361178992\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.0179457894104826\n",
            "\n",
            "Epoch : 6/20.. Training loss: 0.9420192292736619\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.8687216844362067\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.8214973922428268\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.7671693013718975\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.7185524099261102\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.6777689084791771\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.6451435598933026\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6160544495067328\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.584836756053102\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.5547972078842428\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5318351630216746\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.4951695369251663\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.48259905952474347\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.4543237695732461\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.43789969824368846\n",
            "Model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpY8ktdskRQN",
        "colab_type": "code",
        "outputId": "01f77201-11a0-4a24-ce55-7a531eb6b4f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Target Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = target_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 77 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEClKFqikmUl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_VqRVVkoCm",
        "colab_type": "code",
        "outputId": "5e92960e-b9fe-440d-e8f8-1d0375db3bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "# for the first ICP, your shadow model can have the same CNN architecture and hyperparameters\n",
        "\n",
        "shadow_model = CNN()\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()\n",
        "#send to GPU\n",
        "shadow_model = shadow_model.cuda()\n",
        "shadow_criterion =  nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "shadow_optimizer = optim.Adam(shadow_model.parameters(), lr=0.0003) # ADAM \n",
        "\n",
        "\n",
        "# let the magic begin\n",
        "epochs = 20\n",
        "with torch.set_grad_enabled(True):\n",
        "  for e in range(epochs):\n",
        "      running_loss = 0\n",
        "      for images, labels in shadow_train_loader:\n",
        "          # sending tensors to GPU\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "          shadow_optimizer.zero_grad()\n",
        "          logits = shadow_model(images)\n",
        "          shadow_loss = shadow_criterion(logits, labels)\n",
        "          shadow_loss.backward()\n",
        "          shadow_optimizer.step()\n",
        "\n",
        "\n",
        "          running_loss += shadow_loss.item()\n",
        "      else:\n",
        "          print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(shadow_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Our model: \\n\\n\", shadow_model, '\\n')\n",
        "torch.save(shadow_model.state_dict(), project_path+'/shadow_checkpoint.pth')\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.8152915897881587\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.4869877214322005\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.3030839470951148\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.1851700192979535\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.0905567648465677\n",
            "\n",
            "Epoch : 6/20.. Training loss: 1.007945784179451\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.9269451595404569\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.8852235023932689\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.826741272626478\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.7707388960491971\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.719840779424171\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.7001564950132004\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6560657263669135\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.6288866145950754\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.6087105634534146\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5696254600687405\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.5456405857392131\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.5213719619452344\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.49775030152143346\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.48102178511536103\n",
            "Our model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0kP_-62ljFE",
        "colab_type": "code",
        "outputId": "55a2090c-f679-40bd-b7d1-eba2d3eac58c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Shadow Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 75 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ymKnj7QpdDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = CNN()\n",
        "    model.load_state_dict(checkpoint)\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J1B1OhMp6er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaD8_N34l3Eh",
        "colab_type": "code",
        "outputId": "81b49238-3e0a-462e-c1a1-07635d1585bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#load the model\n",
        "load_shadow_model = load_checkpoint(project_path+'/shadow_checkpoint.pth')\n",
        "load_shadow_model = load_shadow_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "\n",
        "labels_0 = 0#np.zeros(1)\n",
        "labels_1 = 1#np.ones(1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "print(predictions[0])  \n",
        "print(predictions[17000])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([1.03256614e-04, 2.75987560e-07, 2.06277327e-04, 3.30030656e-04,\n",
            "       1.36835722e-03, 1.91890495e-03, 4.24083652e-07, 9.96042490e-01,\n",
            "       2.56733892e-06, 2.75278380e-05], dtype=float32), 1]\n",
            "[array([3.1399410e-02, 2.1190448e-05, 2.2439783e-02, 1.4885777e-01,\n",
            "       6.6391683e-01, 3.6686409e-02, 7.1530598e-03, 8.8585056e-02,\n",
            "       3.6914332e-04, 5.7121448e-04], dtype=float32), 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhaKjRRUl6Po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new dataset of the shape [predictions(shadow_in), 1], [predicitons(shadow_out), 0] and zip them together\n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/shadow.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl56BLIpl8Nl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "#load the model\n",
        "load_target_model = load_checkpoint(project_path+'/target_checkpoint.pth')\n",
        "load_target_model = load_target_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_target_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "label_size = (1,1)\n",
        "\n",
        "labels_0 = 0\n",
        "labels_1 = 1\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/target.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yEnRcZW6sUY",
        "colab_type": "code",
        "outputId": "84c453c1-907e-4c02-a30a-520803e79b9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UZ2tfJzl94s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/shadow.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    predictionsList = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJFbXp8umAam",
        "colab_type": "code",
        "outputId": "44d4ce51-8f18-436a-8fd0-b9935b278c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_size = len(predictionsList)\n",
        "split1 = total_size // 4\n",
        "split1 = total_size - split1 \n",
        "split2 = split1*2\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "train_idx = indices[:] \n",
        "test_idx = indices[split1:] \n",
        "print(f'No.of train date {len(train_idx)} and No.of test data {len(test_idx)}')\n",
        "batch_size = 10 # pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "train_sampler = SubsetRandomSampler(train_idx) # Pytorch function\n",
        "train_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "test_sampler = SubsetRandomSampler(test_idx) # Pytorch function\n",
        "test_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=test_sampler)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of train date 25000 and No.of test data 6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU012hhrmDvi",
        "colab_type": "code",
        "outputId": "857d5c49-47b7-4775-83e5-c4e9243c1369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# create the Attack Model: A NN binary classifier {0, 1}\n",
        "# the input to this model is the propability distribution vector of size 10\n",
        "# and the output is either 0 (input was not included in training) or 1\n",
        "from torch.autograd import Variable\n",
        "attack_model = nn.Sequential(nn.Linear(10, 20),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(20, 26),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(26, 16),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(16, 8),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(8, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "attack_model = attack_model.cuda()\n",
        "attack_criterion = nn.CrossEntropyLoss()\n",
        "attack_optimizer = optim.Adam(attack_model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for outputs, labels in train_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        attack_optimizer.zero_grad()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        #print(pred.data, labels)\n",
        "        loss = attack_criterion(pred, labels)\n",
        "        loss.backward()\n",
        "        attack_optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(predictionsList)}\")\n",
        "        \n",
        "torch.save(attack_model.state_dict(), project_path+'/attack_checkpoint.pth')\n",
        "print('Finished Training the Attack model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.06935151975631713\n",
            "Training loss: 0.06934330963373184\n",
            "Training loss: 0.06933639912128449\n",
            "Training loss: 0.06932635615348816\n",
            "Training loss: 0.06932766935825348\n",
            "Finished Training the Attack model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWR_CXQEmIC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    validation = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecc2gaFmHnoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1 # pick your own\n",
        "\n",
        "validation_sampler = SubsetRandomSampler(indices[6250:18250]) # randomly picking 5000 data items\n",
        "validation_loader = torch.utils.data.DataLoader(validation, batch_size=batch_size, sampler=validation_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haNVIg-FHsFv",
        "colab_type": "code",
        "outputId": "c80070f8-085d-4598-b250-e20e36160587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "total = 0\n",
        "tp = 0\n",
        "tn = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "with torch.no_grad():\n",
        "    for outputs, labels in validation_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        predicted = torch.argmax(pred.data)\n",
        "        #print('\\n',pred.data, predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.item() == labels.item())\n",
        "        tp += ((predicted.item() == labels.item()) and (predicted.item() == 1))\n",
        "        tn += ((predicted.item() == labels.item()) and (predicted.item() == 0))\n",
        "        fp += ((predicted.item() != labels.item()) and (predicted.item() == 1))\n",
        "        fn += ((predicted.item() != labels.item()) and (predicted.item() == 0))\n",
        "        #print(predicted.item(),labels.item(),correct)\n",
        "incorrect = total- correct\n",
        "print(f'TP : {tp}, TN : {tn}, FP : {fp}, FN : {fn}')\n",
        "pre = tp/(tp+fp)\n",
        "rec = tp/(tp+fn)\n",
        "print(f'Precision {pre*100}')\n",
        "print(f'Recall {rec*100}')\n",
        "print(f'F1 Score {2*((pre*rec)/(pre+rec))*100}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TP : 6250, TN : 0, FP : 5750, FN : 0\n",
            "Precision 52.083333333333336\n",
            "Recall 100.0\n",
            "F1 Score 68.4931506849315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMsyCgziqeaa",
        "colab_type": "text"
      },
      "source": [
        "Great! At this point, you must have created a succesfful attack model that can detect whether a datapoint was used in training a target mode or not. \n",
        "* A successful attack model is one with a precision/recall higher than 85% -- you are using same architecture and are aware of the data classes\n",
        "\n",
        " \n",
        " Can you suggest any defense mechanism? If yes, Apply them to your solution and re-evaluate your attack model. How did your defense mecanism affect the accuracy of the target model? How did it affect the recall and precision of the Attack model?"
      ]
    }
  ]
}