{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Membership Attack - solution guidelines.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saisampathkumar/AI-Cybersecurity/blob/master/ICP10/Membership_Attack_solution_guidelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvK6LaVhrfZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05dkTKAsEh-",
        "colab_type": "code",
        "outputId": "b9088288-dad2-47de-9acf-5f9b6b2b31ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/My Drive/cybersecurity'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEW1mLverl7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images, nothing much is needed here. \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjsFJTFwr1wV",
        "colab_type": "code",
        "outputId": "ebf27949-a4bc-41d3-d15b-0621541aec10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/drive/My Drive/cybersecurity/data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:06, 26209864.54it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itY7G_y3tDnC",
        "colab_type": "code",
        "outputId": "32be176c-f3dd-4f81-e939-6b13ee674c34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "source": [
        "\n",
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " bird  bird  bird   car\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nR53Av9A9PDw86gT+he7h4eFRJ/j/kPhO0vAMrlsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJK32k42gbEK",
        "colab_type": "code",
        "outputId": "990ba4a6-ba43-4cd4-b0b3-f3fc51c51ba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx =  indices[split3:]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 12500 25000 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wJ_0lkhp76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj9LuQJNuCXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O39H-xzClPgh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6a21fb33-9323-4958-f0ee-a56ea1ad80b5"
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER_B4V8YjKyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb722b6e-02f0-4732-dcf0-e8633318aeba"
      },
      "source": [
        "# initalize a target model and train it\n",
        "\n",
        "target_model = CNN()\n",
        "taget_model = target_model.cuda()\n",
        "criterion = nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "optimizer = optim.Adam(target_model.parameters(), lr=0.0003) # try Adam VS SGD\n",
        "\n",
        "    \n",
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        logits = target_model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(target_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Model: \\n\\n\", target_model, '\\n')\n",
        "torch.save(target_model.state_dict(), project_path+'/target_checkpoint.pth')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.8409913139574974\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.5219274866763892\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.3247378030244041\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.182226246046593\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.0672841357529317\n",
            "\n",
            "Epoch : 6/20.. Training loss: 0.9863030911635255\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.9163236729705425\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.84908173612469\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.7978928200995831\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.7478435120504835\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.7200202551834723\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.67036048923631\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6484504325310593\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.6238186855126372\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.6000860153466386\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5630249929235643\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.5469549518755025\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.517935226192636\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.5001873984513685\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.48164258631960966\n",
            "Model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpY8ktdskRQN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ea263e4-d977-4edd-fd1e-c84bb57ee071"
      },
      "source": [
        "# calculate the accuracy of the Target Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = target_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 76 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEClKFqikmUl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_VqRVVkoCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86ea2089-dec0-4cd9-cd6a-f3873c722651"
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "# for the first ICP, your shadow model can have the same CNN architecture and hyperparameters\n",
        "\n",
        "shadow_model = CNN()\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()\n",
        "#send to GPU\n",
        "shadow_model = shadow_model.cuda()\n",
        "shadow_criterion =  nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "shadow_optimizer = optim.Adam(shadow_model.parameters(), lr=0.0003) # ADAM \n",
        "\n",
        "\n",
        "# let the magic begin\n",
        "epochs = 20\n",
        "with torch.set_grad_enabled(True):\n",
        "  for e in range(epochs):\n",
        "      running_loss = 0\n",
        "      for images, labels in shadow_train_loader:\n",
        "          # sending tensors to GPU\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "          shadow_optimizer.zero_grad()\n",
        "          logits = shadow_model(images)\n",
        "          shadow_loss = shadow_criterion(logits, labels)\n",
        "          shadow_loss.backward()\n",
        "          shadow_optimizer.step()\n",
        "\n",
        "\n",
        "          running_loss += shadow_loss.item()\n",
        "      else:\n",
        "          print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(shadow_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Our model: \\n\\n\", shadow_model, '\\n')\n",
        "torch.save(shadow_model.state_dict(), project_path+'/shadow_checkpoint.pth')\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.7883406597025253\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.46769717732049\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.2743873516159594\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.1414818461517544\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.0459267133870698\n",
            "\n",
            "Epoch : 6/20.. Training loss: 0.9736964937366183\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.9050356908832364\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.836166797887029\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.7901117857307425\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.7449418947557964\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.7050055373088479\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.6721860717820085\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6272394576150438\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.6035973194348233\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.5781607155061668\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5397593715344854\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.5224221484340212\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.48862799429489523\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.473077289660073\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.44181642728045467\n",
            "Our model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0kP_-62ljFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f087c345-7052-49d4-f7d5-4db1aaae998d"
      },
      "source": [
        "# calculate the accuracy of the Shadow Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 76 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ymKnj7QpdDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = CNN()\n",
        "    model.load_state_dict(checkpoint)\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J1B1OhMp6er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaD8_N34l3Eh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b4464fbd-928e-44c8-a94f-7e58d93aa300"
      },
      "source": [
        "#load the model\n",
        "load_shadow_model = load_checkpoint(project_path+'/shadow_checkpoint.pth')\n",
        "load_shadow_model = load_shadow_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "\n",
        "labels_0 = 0#np.zeros(1)\n",
        "labels_1 = 1#np.ones(1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "print(predictions[0])  \n",
        "print(predictions[13000])\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([0.00163514, 0.00070957, 0.1440548 , 0.22711812, 0.239183  ,\n",
            "       0.34068605, 0.02096595, 0.02069629, 0.00281851, 0.00213258],\n",
            "      dtype=float32), 1]\n",
            "[array([2.1862559e-11, 5.9348364e-12, 7.2188711e-10, 5.4377470e-08,\n",
            "       4.1996741e-06, 8.3264444e-05, 2.1921696e-10, 9.9991226e-01,\n",
            "       5.8050407e-14, 1.3075264e-11], dtype=float32), 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhaKjRRUl6Po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new dataset of the shape [predictions(shadow_in), 1], [predicitons(shadow_out), 0] and zip them together\n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/shadow.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl56BLIpl8Nl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "#load the model\n",
        "load_target_model = load_checkpoint(project_path+'/target_checkpoint.pth')\n",
        "load_target_model = load_target_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_target_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "label_size = (1,1)\n",
        "\n",
        "labels_0 = 0\n",
        "labels_1 = 1\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/target.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UZ2tfJzl94s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    predictionsList = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJFbXp8umAam",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f4724c5-b8f3-4b35-8628-c7978441185a"
      },
      "source": [
        "total_size = len(predictionsList)\n",
        "split1 = total_size // 3\n",
        "\n",
        "print(total_size, split1)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "train_idx = indices[:split1]\n",
        "test_idx = indices[split1:]\n",
        "\n",
        "batch_size = 32 # pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "train_sampler = SubsetRandomSampler(train_idx) # Pytorch function\n",
        "train_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "test_sampler = SubsetRandomSampler(test_idx) # Pytorch function\n",
        "test_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=test_sampler)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000 8333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU012hhrmDvi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "9b392524-3eee-4b7d-f5f3-f9f2602b5fd2"
      },
      "source": [
        "# create the Attack Model: A NN binary classifier {0, 1}\n",
        "# the input to this model is the propability distribution vector of size 10\n",
        "# and the output is either 0 (input was not included in training) or 1\n",
        "from torch.autograd import Variable\n",
        "attack_model = nn.Sequential(nn.Linear(10, 20),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(20, 26),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(26, 16),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(16, 8),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(8, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "attack_model = attack_model.cuda()\n",
        "attack_criterion = nn.CrossEntropyLoss()\n",
        "attack_optimizer = optim.Adam(attack_model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        # sending tensors to GPU\n",
        "        #images = torch.from_numpy(images).cuda().float()\n",
        "        #labels = torch.from_numpy(labels).cuda().long()\n",
        "        images = images.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        attack_optimizer.zero_grad()\n",
        "        output = attack_model(images)\n",
        "        #output = torch.argmax(output,dim=1)\n",
        "        #print(output,labels)\n",
        "        loss = attack_criterion(output, labels)\n",
        "        loss.backward()\n",
        "        attack_optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(predictionsList)}\")\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.0020351949696871454\n",
            "Training loss: 1.2132326913706493e-06\n",
            "Training loss: 2.2152284895128105e-07\n",
            "Training loss: 7.493773435271578e-08\n",
            "Training loss: 3.4991176335097406e-08\n",
            "Training loss: 1.937092095886328e-08\n",
            "Training loss: 1.1760835629957e-08\n",
            "Training loss: 7.74309837652254e-09\n",
            "Training loss: 5.389026297279997e-09\n",
            "Training loss: 3.949540463281664e-09\n",
            "Training loss: 2.8775971270533774e-09\n",
            "Training loss: 2.1986889800018616e-09\n",
            "Training loss: 1.657937403933829e-09\n",
            "Training loss: 1.4110137428247072e-09\n",
            "Training loss: 1.2000706502135472e-09\n",
            "Training loss: 9.082715510544403e-10\n",
            "Training loss: 5.710582980356094e-10\n",
            "Training loss: 3.118010399472126e-10\n",
            "Training loss: 1.915486812809064e-10\n",
            "Training loss: 1.680048483887475e-10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWR_CXQEmIC5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e2ad756-0e5c-416d-b7d9-4fe480564a07"
      },
      "source": [
        "# calculate the accuracy of the attack Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        outputs = attack_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 25 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecc2gaFmHnoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    validation = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrbdohySHptb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32 # pick your own\n",
        "\n",
        "validation_loader = torch.utils.data.DataLoader(validation, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haNVIg-FHsFv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03a776ac-d07e-4169-a6e5-2d6790a89fa0"
      },
      "source": [
        "#input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in validation_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        outputs = attack_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 50 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMsyCgziqeaa",
        "colab_type": "text"
      },
      "source": [
        "Great! At this point, you must have created a succesfful attack model that can detect whether a datapoint was used in training a target mode or not. \n",
        "* A successful attack model is one with a precision/recall higher than 85% -- you are using same architecture and are aware of the data classes\n",
        "\n",
        " \n",
        " Can you suggest any defense mechanism? If yes, Apply them to your solution and re-evaluate your attack model. How did your defense mecanism affect the accuracy of the target model? How did it affect the recall and precision of the Attack model?"
      ]
    }
  ]
}